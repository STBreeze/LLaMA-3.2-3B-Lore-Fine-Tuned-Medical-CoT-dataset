{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install unsloth wandb rouge-score bitsandbytes tyro trl --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:43:40.752515Z","iopub.execute_input":"2025-05-27T15:43:40.752778Z","iopub.status.idle":"2025-05-27T15:46:46.813152Z","shell.execute_reply.started":"2025-05-27T15:43:40.752745Z","shell.execute_reply":"2025-05-27T15:46:46.812271Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from unsloth import FastLanguageModel, is_bfloat16_supported\nimport torch\nimport re\nfrom trl import SFTTrainer\nfrom datasets import load_dataset, DatasetDict\nfrom huggingface_hub import login as hf_login\nimport wandb\nfrom transformers import TrainingArguments, Trainer\nfrom rouge_score import rouge_scorer\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:46:46.814940Z","iopub.execute_input":"2025-05-27T15:46:46.815189Z","iopub.status.idle":"2025-05-27T15:47:18.443277Z","shell.execute_reply.started":"2025-05-27T15:46:46.815165Z","shell.execute_reply":"2025-05-27T15:47:18.442654Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-05-27 15:46:57.135882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748360817.310531      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748360817.363508      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load secrets from Kaggle\nsecret = UserSecretsClient()\nhf_token = secret.get_secret(\"HF_Token\")\nwandb_token = secret.get_secret(\"WANDB_Token\")\n\n# Login to Hugging Face and Weights & Biases\nhf_login(token=hf_token)\nwandb.login(key=wandb_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:47:18.443929Z","iopub.execute_input":"2025-05-27T15:47:18.444613Z","iopub.status.idle":"2025-05-27T15:47:25.875470Z","shell.execute_reply.started":"2025-05-27T15:47:18.444593Z","shell.execute_reply":"2025-05-27T15:47:25.874820Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstbreeze\u001b[0m (\u001b[33mstbreeze-arch-technologies\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Define prompt template\nprompt_style = '''Here is an instruction that describes a task, along with an input that provides further context. Write an appropriate response that fulfills the request. Before answering, you must think carefully about the question and create a step-by-step chain of thought to ensure your responses are logical & accurate. Make sure that the chain of thought is written between the think tags and the concluding response is between the response tags (do not overlap). Ensure your tone is professional yet easily understandable.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics & treatment planning. Additionally, you are also an expert in communication with advanced skills in conveying responses that are meaningful, respectful & highly valuable. Please answer the following medical question.\n\n### Question: {}\n\n### Response:\n<think> {} </think>\n<response> {} </response>'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:47:25.877016Z","iopub.execute_input":"2025-05-27T15:47:25.877715Z","iopub.status.idle":"2025-05-27T15:47:25.882241Z","shell.execute_reply.started":"2025-05-27T15:47:25.877693Z","shell.execute_reply":"2025-05-27T15:47:25.881312Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load model and tokenizer\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n    max_seq_length = 2048,\n    dtype = None,\n    load_in_4bit = True,\n    token = hf_token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:47:25.883134Z","iopub.execute_input":"2025-05-27T15:47:25.883557Z","iopub.status.idle":"2025-05-27T15:48:14.350758Z","shell.execute_reply.started":"2025-05-27T15:47:25.883530Z","shell.execute_reply":"2025-05-27T15:48:14.350183Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.5.7: Fast Llama patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 6.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"948037a4bb0b4eea807e696d394037b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cd7f2f7f33d4a9d9f753f27d5d19fa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af48435a2b3467096a5c31276eef34c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ecad9ff025c45ab958cccf8c256e5bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44c961b739642b789e5362f0eb7b27d"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Load dataset\nds = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", 'en', split=\"train\")\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:48:14.351413Z","iopub.execute_input":"2025-05-27T15:48:14.351671Z","iopub.status.idle":"2025-05-27T15:48:21.175818Z","shell.execute_reply.started":"2025-05-27T15:48:14.351648Z","shell.execute_reply":"2025-05-27T15:48:21.175249Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d029afad3bd649bebb35d81e57a0db8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/58.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6679cdeeefe74601b52c773827ef6ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/19704 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37577392c8c7425ab284d89a0b1c20e8"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Complex_CoT', 'Response'],\n    num_rows: 19704\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Format dataset to fit the prompt style\neos = tokenizer.eos_token\n\ndef prompt_format (example):\n    formatted_prompt = prompt_style.format(example['Question'], example['Complex_CoT'], example['Response']) + eos\n    return {'prompt': formatted_prompt}\n    \nds_tuned = ds.map(lambda x: prompt_format(x))\nds_tuned.to_json('Prompt Formatted Medical Dataset.jsonl')\nprint(ds_tuned['prompt'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:48:21.176545Z","iopub.execute_input":"2025-05-27T15:48:21.176820Z","iopub.status.idle":"2025-05-27T15:48:24.156050Z","shell.execute_reply.started":"2025-05-27T15:48:21.176798Z","shell.execute_reply":"2025-05-27T15:48:24.155389Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19704 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc09ec52f78b4629a7e9323d0d507d7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating json from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdbd0dbd1fb34a699afee49d4a454be1"}},"metadata":{}},{"name":"stdout","text":"Here is an instruction that describes a task, along with an input that provides further context. Write an appropriate response that fulfills the request. Before answering, you must think carefully about the question and create a step-by-step chain of thought to ensure your responses are logical & accurate. Make sure that the chain of thought is written between the think tags and the concluding response is between the response tags (do not overlap). Ensure your tone is professional yet easily understandable.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics & treatment planning. Additionally, you are also an expert in communication with advanced skills in conveying responses that are meaningful, respectful & highly valuable. Please answer the following medical question.\n\n### Question: Given the symptoms of sudden weakness in the left arm and leg, recent long-distance travel, and the presence of swollen and tender right lower leg, what specific cardiac abnormality is most likely to be found upon further evaluation that could explain these findings?\n\n### Response:\n<think> Okay, let's see what's going on here. We've got sudden weakness in the person's left arm and leg - and that screams something neuro-related, maybe a stroke?\n\nBut wait, there's more. The right lower leg is swollen and tender, which is like waving a big flag for deep vein thrombosis, especially after a long flight or sitting around a lot.\n\nSo, now I'm thinking, how could a clot in the leg end up causing issues like weakness or stroke symptoms?\n\nOh, right! There's this thing called a paradoxical embolism. It can happen if there's some kind of short circuit in the heart - like a hole that shouldn't be there.\n\nLet's put this together: if a blood clot from the leg somehow travels to the left side of the heart, it could shoot off to the brain and cause that sudden weakness by blocking blood flow there.\n\nHmm, but how would the clot get from the right side of the heart to the left without going through the lungs and getting filtered out?\n\nHere's where our cardiac anomaly comes in: a patent foramen ovale or PFO. That's like a sneaky little shortcut in the heart between the right and left atria.\n\nAnd it's actually pretty common, found in about a quarter of adults, which definitely makes it the top suspect here.\n\nSo with all these pieces - long travel, leg clot, sudden weakness - a PFO fits the bill perfectly, letting a clot cross over and cause all this.\n\nEverything fits together pretty neatly, so I'd bet PFO is the heart issue waiting to be discovered. Yeah, that really clicks into place! </think>\n<response> The specific cardiac abnormality most likely to be found in this scenario is a patent foramen ovale (PFO). This condition could allow a blood clot from the venous system, such as one from a deep vein thrombosis in the leg, to bypass the lungs and pass directly into the arterial circulation. This can occur when the clot moves from the right atrium to the left atrium through the PFO. Once in the arterial system, the clot can travel to the brain, potentially causing an embolic stroke, which would explain the sudden weakness in the left arm and leg. The connection between the recent travel, which increases the risk of deep vein thrombosis, and the neurological symptoms suggests the presence of a PFO facilitating a paradoxical embolism. </response><|eot_id|>\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Split the dataset into train & test sets\nds_dict = ds_tuned.train_test_split(test_size=100, seed=42, shuffle=True)\nds_train = ds_dict['train']\nds_eval = ds_dict['test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:48:24.156857Z","iopub.execute_input":"2025-05-27T15:48:24.157148Z","iopub.status.idle":"2025-05-27T15:48:24.171614Z","shell.execute_reply.started":"2025-05-27T15:48:24.157129Z","shell.execute_reply":"2025-05-27T15:48:24.171060Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Apply LoRA fine tuning to the model\nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r = 16,\n    lora_alpha = 32,\n    lora_dropout = 0,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:48:24.172340Z","iopub.execute_input":"2025-05-27T15:48:24.172572Z","iopub.status.idle":"2025-05-27T15:48:31.409132Z","shell.execute_reply.started":"2025-05-27T15:48:24.172556Z","shell.execute_reply":"2025-05-27T15:48:31.408588Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.5.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Setup training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"Outputs\",\n    per_device_train_batch_size = 2,\n    per_device_eval_batch_size = 2,\n    gradient_accumulation_steps = 4,\n    warmup_steps = 5,\n    max_steps = 50,\n    learning_rate = 2e-4,\n    num_train_epochs = 1,\n    bf16 = is_bfloat16_supported(),\n    fp16 = not is_bfloat16_supported(),\n    logging_steps = 10,\n    optim = 'adamw_8bit',\n    weight_decay = 0.01,\n    lr_scheduler_type = 'linear',\n    seed = 3407,\n    report_to = 'wandb',\n    run_name = \"medical consultor bot\"\n)\n\n# Initialize fine tuning trainer\ntrainer = SFTTrainer(\n    model = model_lora,\n    tokenizer = tokenizer,\n    train_dataset = ds_train,\n    eval_dataset = ds_eval,\n    dataset_text_field = 'prompt',\n    max_seq_length = 2048,\n    dataset_num_proc = 2,\n    args = training_args\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:48:31.411010Z","iopub.execute_input":"2025-05-27T15:48:31.411221Z","iopub.status.idle":"2025-05-27T15:48:57.445014Z","shell.execute_reply.started":"2025-05-27T15:48:31.411205Z","shell.execute_reply":"2025-05-27T15:48:57.444387Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"prompt\"] (num_proc=2):   0%|          | 0/19604 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11a4962d9fa945bd9c565e3e14093d14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"prompt\"] (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f724fdeeb8a9473b85aaf587ce852dc4"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Start training!\ntrainer_summary = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:48:57.445981Z","iopub.execute_input":"2025-05-27T15:48:57.446300Z","iopub.status.idle":"2025-05-27T16:06:31.248469Z","shell.execute_reply.started":"2025-05-27T15:48:57.446248Z","shell.execute_reply":"2025-05-27T16:06:31.247941Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 19,604 | Num Epochs = 1 | Total steps = 50\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250527_154859-gku66xzb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/stbreeze-arch-technologies/huggingface/runs/gku66xzb' target=\"_blank\">medical consultor bot</a></strong> to <a href='https://wandb.ai/stbreeze-arch-technologies/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/stbreeze-arch-technologies/huggingface' target=\"_blank\">https://wandb.ai/stbreeze-arch-technologies/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/stbreeze-arch-technologies/huggingface/runs/gku66xzb' target=\"_blank\">https://wandb.ai/stbreeze-arch-technologies/huggingface/runs/gku66xzb</a>"},"metadata":{}},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 16:56, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.818500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.312800</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.266900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.245200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.199700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:31.249357Z","iopub.execute_input":"2025-05-27T16:06:31.250050Z","iopub.status.idle":"2025-05-27T16:06:33.222293Z","shell.execute_reply.started":"2025-05-27T16:06:31.250028Z","shell.execute_reply":"2025-05-27T16:06:33.221581Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▃▄▆██</td></tr><tr><td>train/global_step</td><td>▁▃▅▆██</td></tr><tr><td>train/grad_norm</td><td>█▁▁▂▁</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>5758461346394112.0</td></tr><tr><td>train/epoch</td><td>0.0204</td></tr><tr><td>train/global_step</td><td>50</td></tr><tr><td>train/grad_norm</td><td>0.31147</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1997</td></tr><tr><td>train_loss</td><td>1.36861</td></tr><tr><td>train_runtime</td><td>1051.4616</td></tr><tr><td>train_samples_per_second</td><td>0.38</td></tr><tr><td>train_steps_per_second</td><td>0.048</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">medical consultor bot</strong> at: <a href='https://wandb.ai/stbreeze-arch-technologies/huggingface/runs/gku66xzb' target=\"_blank\">https://wandb.ai/stbreeze-arch-technologies/huggingface/runs/gku66xzb</a><br> View project at: <a href='https://wandb.ai/stbreeze-arch-technologies/huggingface' target=\"_blank\">https://wandb.ai/stbreeze-arch-technologies/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250527_154859-gku66xzb/logs</code>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"new_prompt_style = '''Here is an instruction that describes a task, along with an input that provides further context. Write an appropriate response that fulfills the request. Before answering, you must think carefully about the question and create a step-by-step chain of thought to ensure your responses are logical & accurate. Make sure that the chain of thought is written between the think tags and the concluding response is between the response tags (do not overlap). Ensure your tone is professional yet easily understandable.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics & treatment planning. Additionally, you are also an expert in communication with advanced skills in conveying responses that are meaningful, respectful & highly valuable. Please answer the following medical question.\n\n### Question: {}\n\n### Response:\n<think>'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:33.223118Z","iopub.execute_input":"2025-05-27T16:06:33.223433Z","iopub.status.idle":"2025-05-27T16:06:33.227455Z","shell.execute_reply.started":"2025-05-27T16:06:33.223408Z","shell.execute_reply":"2025-05-27T16:06:33.226705Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Randomly select 500 entries from the dataset \nsample_ds = ds_tuned.shuffle(seed=42).select(range(50))\n\n# evaluate model function\ndef model_eval (model, dataset):\n    FastLanguageModel.for_inference(model)\n    rougeL_scores = []\n    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n\n    for i in range(len(dataset)):\n        question = dataset['Question'][i]\n        response = dataset['Response'][i]\n        \n        inputs = tokenizer([new_prompt_style.format(question)], return_tensors='pt').to('cuda')\n\n        outputs = model.generate(\n            input_ids = inputs.input_ids,\n            attention_mask = inputs.attention_mask,\n            max_new_tokens = 1200,\n            use_cache = True,\n            eos_token_id = tokenizer.eos_token_id\n        )\n\n        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        match = re.search(r\"<response>(.*?)</response>\", decoded, re.DOTALL)\n        predicted = match.group(1).strip() if match else 'Response N/A'\n\n        # Calculate Score\n        score = scorer.score(response, predicted)\n        rougeL_scores.append(score['rougeL'].fmeasure)\n\n        print(f'Entry {i} complete.')\n\n    avg_score = sum(rougeL_scores) / len(rougeL_scores)\n    return avg_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:33.228338Z","iopub.execute_input":"2025-05-27T16:06:33.228576Z","iopub.status.idle":"2025-05-27T16:06:33.254588Z","shell.execute_reply.started":"2025-05-27T16:06:33.228559Z","shell.execute_reply":"2025-05-27T16:06:33.254048Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"base_model_score = model_eval(model, sample_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:33.255430Z","iopub.execute_input":"2025-05-27T16:06:33.255774Z","iopub.status.idle":"2025-05-27T16:25:28.964397Z","shell.execute_reply.started":"2025-05-27T16:06:33.255757Z","shell.execute_reply":"2025-05-27T16:25:28.963717Z"}},"outputs":[{"name":"stdout","text":"Entry 0 complete.\nEntry 1 complete.\nEntry 2 complete.\nEntry 3 complete.\nEntry 4 complete.\nEntry 5 complete.\nEntry 6 complete.\nEntry 7 complete.\nEntry 8 complete.\nEntry 9 complete.\nEntry 10 complete.\nEntry 11 complete.\nEntry 12 complete.\nEntry 13 complete.\nEntry 14 complete.\nEntry 15 complete.\nEntry 16 complete.\nEntry 17 complete.\nEntry 18 complete.\nEntry 19 complete.\nEntry 20 complete.\nEntry 21 complete.\nEntry 22 complete.\nEntry 23 complete.\nEntry 24 complete.\nEntry 25 complete.\nEntry 26 complete.\nEntry 27 complete.\nEntry 28 complete.\nEntry 29 complete.\nEntry 30 complete.\nEntry 31 complete.\nEntry 32 complete.\nEntry 33 complete.\nEntry 34 complete.\nEntry 35 complete.\nEntry 36 complete.\nEntry 37 complete.\nEntry 38 complete.\nEntry 39 complete.\nEntry 40 complete.\nEntry 41 complete.\nEntry 42 complete.\nEntry 43 complete.\nEntry 44 complete.\nEntry 45 complete.\nEntry 46 complete.\nEntry 47 complete.\nEntry 48 complete.\nEntry 49 complete.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"lora_model_score = model_eval(model_lora, sample_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:25:28.965339Z","iopub.execute_input":"2025-05-27T16:25:28.965632Z","iopub.status.idle":"2025-05-27T16:45:09.426893Z","shell.execute_reply.started":"2025-05-27T16:25:28.965607Z","shell.execute_reply":"2025-05-27T16:45:09.425968Z"}},"outputs":[{"name":"stdout","text":"Entry 0 complete.\nEntry 1 complete.\nEntry 2 complete.\nEntry 3 complete.\nEntry 4 complete.\nEntry 5 complete.\nEntry 6 complete.\nEntry 7 complete.\nEntry 8 complete.\nEntry 9 complete.\nEntry 10 complete.\nEntry 11 complete.\nEntry 12 complete.\nEntry 13 complete.\nEntry 14 complete.\nEntry 15 complete.\nEntry 16 complete.\nEntry 17 complete.\nEntry 18 complete.\nEntry 19 complete.\nEntry 20 complete.\nEntry 21 complete.\nEntry 22 complete.\nEntry 23 complete.\nEntry 24 complete.\nEntry 25 complete.\nEntry 26 complete.\nEntry 27 complete.\nEntry 28 complete.\nEntry 29 complete.\nEntry 30 complete.\nEntry 31 complete.\nEntry 32 complete.\nEntry 33 complete.\nEntry 34 complete.\nEntry 35 complete.\nEntry 36 complete.\nEntry 37 complete.\nEntry 38 complete.\nEntry 39 complete.\nEntry 40 complete.\nEntry 41 complete.\nEntry 42 complete.\nEntry 43 complete.\nEntry 44 complete.\nEntry 45 complete.\nEntry 46 complete.\nEntry 47 complete.\nEntry 48 complete.\nEntry 49 complete.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(f\"\\nBase ROUGE-L:\\t{base_model_score:.5f}\")\nprint(f\"\\nLoRA ROUGE-L:\\t{lora_model_score:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:45:09.427928Z","iopub.execute_input":"2025-05-27T16:45:09.428152Z","iopub.status.idle":"2025-05-27T16:45:09.432508Z","shell.execute_reply.started":"2025-05-27T16:45:09.428135Z","shell.execute_reply":"2025-05-27T16:45:09.431705Z"}},"outputs":[{"name":"stdout","text":"\nBase ROUGE-L:\t0.32806\n\nLoRA ROUGE-L:\t0.33147\n","output_type":"stream"}],"execution_count":17}]}